---
title: "Final Project - Macia - 3 - Logistic Regression"
author: "Maçià Bartomeu Llabrés Ferrer"
date: "2023-01-22"
output: html_document
---

We start by loading the previous "prep" file and check if the data is the same.
```{r}
df <- read.csv("FPdata_PREP.csv", stringsAsFactors = TRUE)
str(df)
summary(df)
```

To make the models we first need to know the indexes of the diseases columns. Lets print all of them and count.
```{r}
print(colnames(df))
```

It seems they are from 10 to 19, but we will check it.
```{r}
print(colnames(df)[10:19])
```

As we plan to do regression models it is a good idea to check the class balance of the diseases.
```{r}
library(ggplot2)
p <- list()
for (i in 10:19) {
  print(paste("% for", colnames(df)[i], "(", i-9, ")"))
  t <- table(df[,i])
  print(t/ nrow(df) * 100)
  #barplot(table(df[,i]), col = c("red", "blue"), axes = FALSE, main=colnames(df[i]))
  p[[i-9]] <-  ggplot(data.frame(table(df[,i])), aes(x = Var1, y = Freq)) +
    geom_bar(stat = "identity", fill = c("steelblue", "red") ) +
    geom_text(aes(label = paste0(round(Freq/sum(Freq)*100), "%")), vjust = 1.5) +
    scale_x_discrete(limits = c("0", "1"), labels = NULL) +
    scale_y_continuous(limits = c(0, max(table(df[,i]))), expand = c(0, 0), labels = NULL) +
    theme(axis.line = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          panel.grid = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          plot.title = element_text(hjust = 0.5)) +
    labs(title = colnames(df[i]))
  print(p)
}
#library(gridExtra)
#grid.arrange(grobs = p, ncol = 2)
```
We can clearly see the is not very well balanced, but as this is a first aproach and I really want to test it with clustering. I will first try this way and then I will only balance for "HadArtritis" (as is the one that will have more rows when balanced) and then compare with the "unbalanced" models.

Now using a for loop we can make a logistic regression for each disease. I decided to include all the other variables, because in some cases a disease can also be the consequence of another one. Examples: heart attack, angina and stroke are blood circulation related. Asthma and COPD are both respiratory/lung diseases.
```{r}
glm_list <- list()

for (i in 10:19) {
  formula <- as.formula(paste(colnames(df)[i]," ~ ."))
  
  glm_list[[i-9]] <- glm(formula, data = df, family = binomial)

  print(paste("GLM for", colnames(df)[i], "(", i-9, ")"), sep="")

  glm_summary <- summary(glm_list[[i-9]])
  glm_summary$coefficients <- glm_summary$coefficients[order(glm_summary$coefficients[,4]),]
  print(glm_summary)
}
```

Now that all models are calculated we can check the impact of the race on all the diseases looking at its p value.

**( 1 ) GLM for HadHeartAttack:**

Mainly it can be related to the patient physic condition, but the firsts ethnicities to suffer it are black and multiracial. In the other hand hispanic and white are almost not related to it.

**( 2 ) GLM for HadAngina:**

Heavily influenced by previous heart attacks, but affect in great measure to black people. White and hispanic has also a relevant p value, but much lower. Meanwhile other races and multiracial has practically no relation with it.

**( 3 ) GLM for HadStroke:**

As with angina, heavily influenced by heart attack. Impacts most on hispanic and black ethnicities and a little to multiracial. But white and other races seem to have no direct implication.

**( 4 ) GLM for HadAsthma:**

As previously stated is greatly related to COPD. Multiracial and other race have lower p values. White and above all black ethnicity have no influence on it.

**( 5 ) GLM for HadSkinCancer:**

The main influence is age, but all ethnic groups have a great probability to suffer it. Black, Hispanic and Other race have a negative and great impact on this disease, stating something we already know, darker skin can better resist UV rays. In the other hand white has positive great influence.

**( 6 ) GLM for HadCOPD:**

Heavily influenced by asthma and smokers. Hispanic, Other race and Black being the more relevant and White almost irrelevant.

**( 7 ) GLM for HadDepressiveDisorder:**

Being the only psychic illness it can be predicted very easy with MentalHealthDays. All ethnicities have lower p values for this one, but it's striking how black (negative) and white (positive) have opposite estimate.

**( 8 ) GLM for HadKidneyDisease:**

As supposed is very influenced by also having diabetes. The regression can only make a strong prediction for black ethnicity, the other ones, specially, other race and white have virtually no effect.

**( 9 ) GLM for HadArthritis:**

Has a great influence by depression, meaning it is an illness with a heavy impact on your mental health. While the model can almost predict having the disease for every ethnicity, it is shocking how Hispanic and White have the same p values but with opposites estimate (Hispanic being negative). 

**( 10 ) GLM for HadDiabetes:**

Other race, hispanic and black all have the minimum p value and a z value greater than 10.

In general we see that ethnicity it isn't in the top half of the list for the diseases. GeneralHealth, Age and gender usually are more important (top 5/10 in most cases). But almost in every case we see some kind of "genetic" influence. Being specially relevant for skin cancer, where 4 of 5 ethnic groups are among the top 15 relevant variables from 44 including all the etnicities levels, when usually the first one appears after that same number (15).

As stated before now I will balance the dataset for "HadArtritis" by downsampling it and compare both models.
```{r}
set.seed(123)

min_samples <- min(table(df$HadArthritis))

df_balanced <- data.frame()

for(level in unique(df$HadArthritis)) {
  df_level <- df[df$HadArthritis == level, ]
  
  df_sample <- df_level[sample(nrow(df_level), min_samples), ]
  
  df_balanced <- rbind(df_balanced, df_sample)
}
print("Count for HadArthritis levels:")
table(df_balanced$HadArthritis)
```

Now with the new balanced dataset it is time to make another model and compare with the original.
```{r}
glm_balanced <- glm(HadArthritis ~ ., data = df_balanced, family = binomial)

print("GLM for HadArthritis balanced ( 11 )")

glm_summary <- summary(glm_balanced)
glm_summary$coefficients <- glm_summary$coefficients[order(glm_summary$coefficients[,4]),]
print(glm_summary)

print("GLM for HadArthritis unbalanced ( 12 )")

glm_summary <- summary(glm_list[[9]])
glm_summary$coefficients <- glm_summary$coefficients[order(glm_summary$coefficients[,4]),]
print(glm_summary)
```
We can see the results differ a bit, but not so much. Hispanic, White only and Multiracial have almost exact results. Other race and Black seems to interchange values. Taking into consideration the "random" nature of any sampling process I do not think the extra effort of making a balanced dataset for every disease is worth it.
